{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJ64I0fC5bQYULDeD9BCa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sugirjan/CreditApprovalPrediction/blob/master/NN_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2T6V90FQ4aU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0eab0f81-5a3b-4407-edff-7f57adbbaa4e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doatiNJTYbRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8257f82e-0d02-4836-b643-8580c18ca41b"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/NNAssignment/cc_approval.csv', header=None);\n",
        "df.info()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    object \n",
            " 1   1       690 non-null    object \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    object \n",
            " 4   4       690 non-null    object \n",
            " 5   5       690 non-null    object \n",
            " 6   6       690 non-null    object \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    object \n",
            " 9   9       690 non-null    object \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    object \n",
            " 12  12      690 non-null    object \n",
            " 13  13      690 non-null    object \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHaA0_k3RT6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "751d0e39-b813-4138-f727-4ca69619d7bf"
      },
      "source": [
        "df.columns=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','A16']\n",
        "df.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJONL-eSRz8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7f2428d5-b3e8-4a49-9530-3f4bd653399c"
      },
      "source": [
        "null_cols = ['A1','A2','A4','A5','A6','A7','A14']\n",
        "for col in null_cols:\n",
        "  df[col]=df[col].replace('?',np.NaN)\n",
        "  df[col].fillna(df[col].value_counts().index[0],inplace=True)\n",
        "df.info()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      690 non-null    object \n",
            " 1   A2      690 non-null    object \n",
            " 2   A3      690 non-null    float64\n",
            " 3   A4      690 non-null    object \n",
            " 4   A5      690 non-null    object \n",
            " 5   A6      690 non-null    object \n",
            " 6   A7      690 non-null    object \n",
            " 7   A8      690 non-null    float64\n",
            " 8   A9      690 non-null    object \n",
            " 9   A10     690 non-null    object \n",
            " 10  A11     690 non-null    int64  \n",
            " 11  A12     690 non-null    object \n",
            " 12  A13     690 non-null    object \n",
            " 13  A14     690 non-null    object \n",
            " 14  A15     690 non-null    int64  \n",
            " 15  A16     690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRLa461pVpME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9a7eee11-e854-4d7e-86d2-8375b51fdba1"
      },
      "source": [
        "df.A2 = pd.to_numeric(df[\"A2\"], downcast=\"float\")\n",
        "df.A14 = pd.to_numeric(df[\"A14\"], downcast=\"float\")\n",
        "df.info()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      690 non-null    object \n",
            " 1   A2      690 non-null    float32\n",
            " 2   A3      690 non-null    float64\n",
            " 3   A4      690 non-null    object \n",
            " 4   A5      690 non-null    object \n",
            " 5   A6      690 non-null    object \n",
            " 6   A7      690 non-null    object \n",
            " 7   A8      690 non-null    float64\n",
            " 8   A9      690 non-null    object \n",
            " 9   A10     690 non-null    object \n",
            " 10  A11     690 non-null    int64  \n",
            " 11  A12     690 non-null    object \n",
            " 12  A13     690 non-null    object \n",
            " 13  A14     690 non-null    float32\n",
            " 14  A15     690 non-null    int64  \n",
            " 15  A16     690 non-null    object \n",
            "dtypes: float32(2), float64(2), int64(2), object(10)\n",
            "memory usage: 81.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnxp527xWOxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "outputId": "669cbf19-0d8a-42ac-e63c-0f7b62637543"
      },
      "source": [
        "cat_cols = []\n",
        "cols = df.columns.tolist()\n",
        "for col in cols:\n",
        "\tif df[col].dtype == 'object' and not col=='A16':\n",
        "\t\tcat_cols.append(col)\n",
        "\n",
        "data = pd.get_dummies(df, columns=cat_cols)\n",
        "data.info()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A2      690 non-null    float32\n",
            " 1   A3      690 non-null    float64\n",
            " 2   A8      690 non-null    float64\n",
            " 3   A11     690 non-null    int64  \n",
            " 4   A14     690 non-null    float32\n",
            " 5   A15     690 non-null    int64  \n",
            " 6   A16     690 non-null    object \n",
            " 7   A1_a    690 non-null    uint8  \n",
            " 8   A1_b    690 non-null    uint8  \n",
            " 9   A4_l    690 non-null    uint8  \n",
            " 10  A4_u    690 non-null    uint8  \n",
            " 11  A4_y    690 non-null    uint8  \n",
            " 12  A5_g    690 non-null    uint8  \n",
            " 13  A5_gg   690 non-null    uint8  \n",
            " 14  A5_p    690 non-null    uint8  \n",
            " 15  A6_aa   690 non-null    uint8  \n",
            " 16  A6_c    690 non-null    uint8  \n",
            " 17  A6_cc   690 non-null    uint8  \n",
            " 18  A6_d    690 non-null    uint8  \n",
            " 19  A6_e    690 non-null    uint8  \n",
            " 20  A6_ff   690 non-null    uint8  \n",
            " 21  A6_i    690 non-null    uint8  \n",
            " 22  A6_j    690 non-null    uint8  \n",
            " 23  A6_k    690 non-null    uint8  \n",
            " 24  A6_m    690 non-null    uint8  \n",
            " 25  A6_q    690 non-null    uint8  \n",
            " 26  A6_r    690 non-null    uint8  \n",
            " 27  A6_w    690 non-null    uint8  \n",
            " 28  A6_x    690 non-null    uint8  \n",
            " 29  A7_bb   690 non-null    uint8  \n",
            " 30  A7_dd   690 non-null    uint8  \n",
            " 31  A7_ff   690 non-null    uint8  \n",
            " 32  A7_h    690 non-null    uint8  \n",
            " 33  A7_j    690 non-null    uint8  \n",
            " 34  A7_n    690 non-null    uint8  \n",
            " 35  A7_o    690 non-null    uint8  \n",
            " 36  A7_v    690 non-null    uint8  \n",
            " 37  A7_z    690 non-null    uint8  \n",
            " 38  A9_f    690 non-null    uint8  \n",
            " 39  A9_t    690 non-null    uint8  \n",
            " 40  A10_f   690 non-null    uint8  \n",
            " 41  A10_t   690 non-null    uint8  \n",
            " 42  A12_f   690 non-null    uint8  \n",
            " 43  A12_t   690 non-null    uint8  \n",
            " 44  A13_g   690 non-null    uint8  \n",
            " 45  A13_p   690 non-null    uint8  \n",
            " 46  A13_s   690 non-null    uint8  \n",
            "dtypes: float32(2), float64(2), int64(2), object(1), uint8(40)\n",
            "memory usage: 59.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkMi3Y-4bhAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A16 = {'+':1,'-':0}\n",
        "data.A16 = [A16[status] for status in data.A16]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z6AkeZRdmyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5bfdff50-7eaa-4d00-fd33-ec171ddea632"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A8</th>\n",
              "      <th>A11</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "      <th>A1_a</th>\n",
              "      <th>A1_b</th>\n",
              "      <th>A4_l</th>\n",
              "      <th>A4_u</th>\n",
              "      <th>A4_y</th>\n",
              "      <th>A5_g</th>\n",
              "      <th>A5_gg</th>\n",
              "      <th>A5_p</th>\n",
              "      <th>A6_aa</th>\n",
              "      <th>A6_c</th>\n",
              "      <th>A6_cc</th>\n",
              "      <th>A6_d</th>\n",
              "      <th>A6_e</th>\n",
              "      <th>A6_ff</th>\n",
              "      <th>A6_i</th>\n",
              "      <th>A6_j</th>\n",
              "      <th>A6_k</th>\n",
              "      <th>A6_m</th>\n",
              "      <th>A6_q</th>\n",
              "      <th>A6_r</th>\n",
              "      <th>A6_w</th>\n",
              "      <th>A6_x</th>\n",
              "      <th>A7_bb</th>\n",
              "      <th>A7_dd</th>\n",
              "      <th>A7_ff</th>\n",
              "      <th>A7_h</th>\n",
              "      <th>A7_j</th>\n",
              "      <th>A7_n</th>\n",
              "      <th>A7_o</th>\n",
              "      <th>A7_v</th>\n",
              "      <th>A7_z</th>\n",
              "      <th>A9_f</th>\n",
              "      <th>A9_t</th>\n",
              "      <th>A10_f</th>\n",
              "      <th>A10_t</th>\n",
              "      <th>A12_f</th>\n",
              "      <th>A12_t</th>\n",
              "      <th>A13_g</th>\n",
              "      <th>A13_p</th>\n",
              "      <th>A13_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.830000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>202.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58.669998</td>\n",
              "      <td>4.460</td>\n",
              "      <td>3.04</td>\n",
              "      <td>6</td>\n",
              "      <td>43.0</td>\n",
              "      <td>560</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.500000</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>824</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.830000</td>\n",
              "      <td>1.540</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.170000</td>\n",
              "      <td>5.625</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          A2     A3    A8  A11    A14  ...  A12_f  A12_t  A13_g  A13_p  A13_s\n",
              "0  30.830000  0.000  1.25    1  202.0  ...      1      0      1      0      0\n",
              "1  58.669998  4.460  3.04    6   43.0  ...      1      0      1      0      0\n",
              "2  24.500000  0.500  1.50    0  280.0  ...      1      0      1      0      0\n",
              "3  27.830000  1.540  3.75    5  100.0  ...      0      1      1      0      0\n",
              "4  20.170000  5.625  1.71    0  120.0  ...      1      0      0      0      1\n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMXuItm8doWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy \n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 5\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F7piHWK6YrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "  def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "    Only computes a batch-wise average of recall. Computes the recall, a metric for multi-label classification of how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "  def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "    Only computes a batch-wise average of precision. Computes the precision, a metric for multi-label classification of how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "  precision = precision(y_true, y_pred)\n",
        "  recall = recall(y_true, y_pred)\n",
        "  return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA3xZiqbuHvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline model for the neural network. We choose a hidden layer of 10 neurons. The lesser number of neurons helps to eliminate the redundancies in the data and select \n",
        "# the more important features.\n",
        "def create_baseline(activation1 = 'relu', activation2 = 'sigmoid', no_features = 46, no_neurons = 46):\n",
        "    # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(no_neurons, input_dim=no_features, kernel_initializer='normal', activation=activation1))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation=activation2))\n",
        "\n",
        "  # Compile model. We use the the logarithmic loss function, and the Adam gradient optimizer.\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smsu9yPtvFF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "eb0010d6-2940-44b5-9a7f-539aefb8237c"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "y = data.A16\n",
        "X = data.copy().drop('A16', axis=1)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state= 5)\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 83.19% (3.12%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF581WQZFrL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95caadcf-c0d0-4594-e03b-7add27069911"
      },
      "source": [
        "def create_baseline_params_redued_neurons():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_redued_neurons, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 83.62% (3.13%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrxnBQjdYk16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4591f700-6d1b-4d09-f5b8-965760ec710f"
      },
      "source": [
        "def create_baseline_params_increased_neurons():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_increased_neurons, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 81.59% (2.92%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CBQ3SJhhw8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7a612fc7-78be-4015-d8fc-45993669b2af"
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 49.28% (2.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Jdhtk0wqVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ae45c656-967d-4f9a-e417-4856201cc0bf"
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 52.17% (3.97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT6nxjWSzCTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e8404d6f-aea4-45fa-d727-bf597b5f8a0b"
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 48.55% (2.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3LKCESkt6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "076d1d80-c2ae-46c0-c103-95944b5dc8a6"
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-490d1ac2579c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mlp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_baseline_params_without_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3784\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3785\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3786\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    267\u001b[0m   \u001b[0;34m\"\"\"Implementation of constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtS1Q5C-wyNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYDgBQXhzI_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e47aad78-d2b3-47f1-bb37-aa5f30acf059"
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 84.93% (2.57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b7RZ7kDlFq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_tanh_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1, activation='tanh'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4XsWarw_e6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUljuqNfw4i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJcE23XhzOar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Tf2XOz6UgB",
        "colab_type": "text"
      },
      "source": [
        "2 layer NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmYP47ApEc2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7NSownf86Jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCDkq_1E888g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LGhIJkpE-su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFVjILkdGCB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm7eodSXIlHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9snIz-o9lNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhatcQOT9txN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDMkd7s79v9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCH0saZgJwbs",
        "colab_type": "text"
      },
      "source": [
        "3 NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7UkD7bihDE9w",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eaIDlvqtDE-K",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TAxrLe5-Dm1Y",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jpx2ikn6Dm12",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5iYVIZJPDm2E",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3n6eAMnWDm2R",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGQXnVS_Dm2j",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XBqFDi_vDm2u",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w71jSeW1Dm23",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NoUdRvoJyb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23))\n",
        "  model.add(Dense(12))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojsuHxXKhA0",
        "colab_type": "text"
      },
      "source": [
        "4 NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3AWmNGfLALI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23))\n",
        "  model.add(Dense(12))\n",
        "  model.add(Dense(6))\n",
        "  model.add(Dense(3))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkqRjh0WdmvU",
        "colab_type": "text"
      },
      "source": [
        "Different loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xmT5HsMYLOO8",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pqvD3oK9LOPH",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTxrrTAgLOPM",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_relu_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_relu_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0N7gHXMyLOPS",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7yvMibZELOPV",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fFrXGA68LOPY",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_without_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_without_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eva8D9duLOPb",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iELB1zuDLOPd",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNxfzERkLOPf",
        "colab": {}
      },
      "source": [
        "def create_baseline_params_with_softmax_activation():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_params_with_tanh_activation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKHkaYhLthF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2dnfrbRLuUQ",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5z17KEidLuUd",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cxjZw24dLuUi",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Se0itwVcLuUm",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WCy42NoxLuUr",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kpE_CohLuUu",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ul_ZFQcFLuUx",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXrfS_UsLuUz",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9YO8WOdLuU1",
        "colab": {}
      },
      "source": [
        "def create_2NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_2NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyru4qzjRJ2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uHUgX-GuY_Im",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PESDiIlNY_Iy",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "muGcgwROY_I2",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrkCAcX4Y_I5",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jqSNwdJOY_I9",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x7iFvw-UY_JA",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(23, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "99w8HzFxY_JD",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(23, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b6OoxcTTY_JF",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(46, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RkFLpjv1Y_JH",
        "colab": {}
      },
      "source": [
        "def create_3NN():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(69, input_dim=46))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(69, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_3NN, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}